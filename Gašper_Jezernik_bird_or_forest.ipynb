{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gapac/ML_AI_examples/blob/main/Ga%C5%A1per_Jezernik_bird_or_forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0tJcuqm8Aj3"
      },
      "source": [
        "# Bird or Forest Classification Using Resnet-18 Model\n",
        "\n",
        "#### Main task: Classify images into two categories: **birds** and **forests**.\n",
        "\n",
        "1. Download Images - a set of images belonging to two categories: birds and forests.\n",
        "2. Use Torch Transforms and Torchvision Dataloader - efficient data loading and augmentation\n",
        "3. Load ResNet-18 Model - pre-trained on the ImageNet dataset.\n",
        "4. Alter ResNet-18 Model Architecture - to fit our specific task\n",
        "5. Fine-Tune ResNet-18 Model - training some model layers on our dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kY1-b_88Aj4"
      },
      "source": [
        "### ResNet (Residual Network) Models\n",
        "\n",
        "- Ever since the first CNN-based model, image classification has increasingly useed more layers in deep neural networks\n",
        "\n",
        "- Usually, adding more layers is beneficial, but beyond a certain point, it triggers a common deep learning problem known as the vanishing gradients.\n",
        "\n",
        "- As the gradient values are passed through many layers, they can get smaller and smaller, essentially \"vanishing\" to zero. This makes it very difficult to update the weights in the earlier layers of the network, leading to very slow or stagnant training progress, particularly in networks with many layers.\n",
        "\n",
        "- Residual Connection: In order to solve the problem of the vanishing gradient, this architecture introduced the concept called **skip connections**. The skip connection connects activations of a  layer to further layers by skipping some layers in between. These connections make it easier for gradients to flow back through the network during training, ensuring that even the early layers get updated effectively. This results in faster convergence and often better overall performance.\n",
        "\n",
        "<img src=\"https://github.com/Pubec/ml-workshop/blob/main/resnet/assets/skip_connection.png?raw=true\" alt=\"Plain vs ResNet\" style=\"max-height: 300px;\">\n",
        "\n",
        "<img src=\"https://github.com/Pubec/ml-workshop/blob/main/resnet/assets/normal_resnet.png?raw=true\" alt=\"Plain vs ResNet\" style=\"max-height: 300px;\">\n",
        "\n",
        "\n",
        "- This residual connection enables ResNet networks to be significantly deeper (e.g., 18, 32, ..., 152 ) without performance degradation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksfVh8P-8Aj4"
      },
      "source": [
        "## Step 0: Download dataset\n",
        "\n",
        "We will utilize libraries:\n",
        "- **fast.ai** - image download and verification [https://github.com/fastai/fastai](https://github.com/fastai/fastai)\n",
        "- **dudduckgo_search** for web scraping for imgaes [https://github.com/deedy5/duckduckgo_search](https://github.com/deedy5/duckduckgo_search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tcp7KZM08Aj5"
      },
      "outputs": [],
      "source": [
        "!pip install -q duckduckgo_search fastai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwKGKQET8Aj5"
      },
      "outputs": [],
      "source": [
        "from time import sleep\n",
        "from pathlib import Path\n",
        "\n",
        "from fastai.vision.all import download_images, resize_images, verify_images, get_image_files\n",
        "from duckduckgo_search import DDGS\n",
        "\n",
        "DATASET_PATH = 'bird_or_not'\n",
        "DO_DOWNLOAD = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjR6YYST8Aj5"
      },
      "outputs": [],
      "source": [
        "def search_images(term, max_images=5):\n",
        "    \"\"\"\n",
        "    Search DuckDuckGo Engine to find images by `term` and return their urls (number of limited by `max_images`).\n",
        "    \"\"\"\n",
        "    print(f\"Searching for '{term}'\")\n",
        "    with DDGS() as ddgs:\n",
        "        ddgs_images_gen = ddgs.images(term)\n",
        "        count = 0\n",
        "        ddgs_images_list = []\n",
        "        while count < max_images:\n",
        "            image = ddgs_images_gen[count]\n",
        "            # get image url\n",
        "            url = image.get('image')\n",
        "            # if url containts arguments, remove them\n",
        "            i = url.find(\"?\")\n",
        "            if i > 0:\n",
        "                url = url[:i]\n",
        "            ddgs_images_list.append(url)\n",
        "            count = count+1\n",
        "        return ddgs_images_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIISSAND8Aj6"
      },
      "outputs": [],
      "source": [
        "urls = search_images('bird photos', max_images=5)\n",
        "for url in urls:\n",
        "    print(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVDAjAfi8Aj6"
      },
      "outputs": [],
      "source": [
        "urls = search_images('forest photos', max_images=5)\n",
        "for url in urls:\n",
        "    print(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5a1G5uW8Aj6"
      },
      "source": [
        "### In the next step download images to train-test-validation split\n",
        "\n",
        "1. search for different images of forest and birds\n",
        "2. save images to different folders\n",
        "3. resize images to max_size\n",
        "\n",
        "*NOTE: Pause between searches to prevent crashing*\n",
        "\n",
        "*NOTE: Due to time restricted GPU session, do this part in CPU, then disable downloading to be able to rerun entire session*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF9r2dTW8Aj6"
      },
      "outputs": [],
      "source": [
        "if DO_DOWNLOAD:\n",
        "  searches = ['forest', 'bird']\n",
        "  # Pause between searches to avoid over-loading server\n",
        "  TIME_SLEEP = 0.5\n",
        "\n",
        "  # Training\n",
        "  save_dir = Path(DATASET_PATH) / \"train\"\n",
        "  nr_images = 25\n",
        "  for search_term in searches:\n",
        "      dest = save_dir / search_term\n",
        "      dest.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "      # download 1\n",
        "      term = f'{search_term} photo'\n",
        "      download_images(dest, urls=search_images(term, max_images=nr_images))\n",
        "      print(\"Downloaded\", term)\n",
        "      sleep(TIME_SLEEP)\n",
        "\n",
        "      # download 2\n",
        "      term = f'{search_term} sun photo'\n",
        "      download_images(dest, urls=search_images(term, max_images=nr_images))\n",
        "      print(\"Downloaded\", term)\n",
        "      sleep(TIME_SLEEP)\n",
        "\n",
        "      # donwload 3\n",
        "      term = f'{search_term} shade photo'\n",
        "      download_images(dest, urls=search_images(term, max_images=nr_images))\n",
        "      print(\"Downloaded\", term)\n",
        "      sleep(TIME_SLEEP)\n",
        "\n",
        "      # resize\n",
        "      resize_images(dest, max_size=400, dest=dest)\n",
        "\n",
        "\n",
        "  # Validation\n",
        "  save_dir = Path(DATASET_PATH) / \"val\"\n",
        "  nr_images = 5\n",
        "  for search_term in searches:\n",
        "      dest = save_dir / search_term\n",
        "      dest.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "      # download 1\n",
        "      term = f'{search_term} photography'\n",
        "      download_images(dest, urls=search_images(term, max_images=nr_images))\n",
        "      print(\"Downloaded\", term)\n",
        "      sleep(TIME_SLEEP)\n",
        "\n",
        "      # download 2\n",
        "      term = f'{search_term} sun photography'\n",
        "      download_images(dest, urls=search_images(term, max_images=nr_images))\n",
        "      print(\"Downloaded\", term)\n",
        "      sleep(TIME_SLEEP)\n",
        "\n",
        "      # donwload 3\n",
        "      term = f'{search_term} shade photography'\n",
        "      download_images(dest, urls=search_images(term, max_images=nr_images))\n",
        "      print(\"Downloaded\", term)\n",
        "      sleep(TIME_SLEEP)\n",
        "\n",
        "      # resize\n",
        "      resize_images(dest, max_size=400, dest=dest)\n",
        "\n",
        "\n",
        "  # Test\n",
        "  save_dir = Path(DATASET_PATH) / \"test\"\n",
        "  nr_images = 10\n",
        "  for search_term in searches:\n",
        "      dest = save_dir / search_term\n",
        "      dest.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "      # download 1\n",
        "      term = f'{search_term} image'\n",
        "      download_images(dest, urls=search_images(term, max_images=nr_images))\n",
        "      print(\"Downloaded\", term)\n",
        "      sleep(TIME_SLEEP)\n",
        "\n",
        "      # resize\n",
        "      resize_images(dest, max_size=400, dest=dest)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDJVJfLw8Aj7"
      },
      "outputs": [],
      "source": [
        "# Verify images (check whether can be loaded)\n",
        "\n",
        "path = Path(DATASET_PATH)\n",
        "failed = verify_images(get_image_files(path))\n",
        "for fail in failed:\n",
        "    print(\"could not open:\", fail)\n",
        "failed.map(Path.unlink)\n",
        "print(\"Failed images:\", len(failed))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaK5sOa58Aj7"
      },
      "source": [
        "## Step 1: Load and Augment Dataset\n",
        "\n",
        "We will utilize libraries:\n",
        "- **Torchvision** - to transform or augment data [https://pytorch.org/vision/stable/transforms.html](https://pytorch.org/vision/stable/transforms.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhCUGxhu8Aj7"
      },
      "source": [
        "### Image Folder\n",
        "\n",
        "```bash\n",
        "- train/bird/xxx.png\n",
        "- train/bird/yyy.png\n",
        "- train/forest/xxx.png\n",
        "- train/forest/yyy.png\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISprpOS-8Aj7"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "train_path = Path(DATASET_PATH) / \"train\"\n",
        "\n",
        "train_folder = ImageFolder(train_path)\n",
        "print(train_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFd2qByA8Aj7"
      },
      "outputs": [],
      "source": [
        "print(\"Classes:\", train_folder.classes)\n",
        "print(\"Classes:\", train_folder.class_to_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2FusMpn8Aj7"
      },
      "outputs": [],
      "source": [
        "for img in train_folder.imgs[69:80]:\n",
        "    print(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6Ok1jK38Aj8"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "img_path, img_class = train_folder.imgs[12]\n",
        "\n",
        "image = Image.open(img_path)\n",
        "\n",
        "plt.suptitle(train_folder.classes[img_class])\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS8pZf6o8Aj8"
      },
      "source": [
        "### Transforms\n",
        "\n",
        "- loading\n",
        "- augmentation\n",
        "- chained together using Compose `transforms.Compose`\n",
        "- accepts PIL Image, Tensor Image or batch of Tensor Images as input\n",
        "\n",
        "Note:\n",
        "- Tensor Image Shape: `C x H x W`\n",
        "- Tensor Batch Shape: `B x C x H x W`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MgWH6zm8Aj8"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import transforms\n",
        "\n",
        "# TODO: Try Flip, Rotate, Padding, Crop, ResizeCrop, RandomPerspective, ColorJitter\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    # transforms.Resize(256),\n",
        "    transforms.RandomResizedCrop(112),\n",
        "    # transforms.CenterCrop(224),\n",
        "    # transforms.Pad(padding=50),\n",
        "    # transforms.RandomRotation(120),\n",
        "    # transforms.RandomVerticalFlip(0.5),\n",
        "    # transforms.ColorJitter(brightness=0.1, contrast=0.5, saturation=0.3, hue=0.4),\n",
        "    # transforms.ColorJitter(contrast=(0, 10)),\n",
        "    # transforms.RandomSolarize(threshold=5.0)\n",
        "])\n",
        "\n",
        "transformed_image = transform(image)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(image)\n",
        "ax[1].imshow(transformed_image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZ_eoiNX8Aj8"
      },
      "outputs": [],
      "source": [
        "# Define the transformations to apply to the images during training\n",
        "\n",
        "# Note: Normalize is done by calculating the mean and standard deviation of your dataset images and making your data unit normed.\n",
        "# But, to simplify, just use imagenet dataset's mean and standard deviation to normalize the dataset approximately.\n",
        "# These numbers are imagenet mean and standard deviation!\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWoqWema8Aj8"
      },
      "source": [
        "1. Use Transforms in ImageFolder\n",
        "2. Use ImageFolder in Dataloder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5prUjXHB8Aj9"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# TODO:\n",
        "# train_dataset = ...\n",
        "# val_dataset = ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ky35CVuf8Aj9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# TODO:\n",
        "# check train_dataset loader outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if69nHMW8Aj9"
      },
      "source": [
        "## Step 2: ResNet-18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ir7CwLRs8Aj9"
      },
      "outputs": [],
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epnBvUYV8Aj9"
      },
      "outputs": [],
      "source": [
        "print(\"Number of output layers:\", model.fc.out_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJH_PEy68Aj9"
      },
      "source": [
        "Modify ResNet model output layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_tMj49b8Aj9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# TODO:\n",
        "# alter model.fc output layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WbWsFJT8Aj9"
      },
      "outputs": [],
      "source": [
        "print(\"Number of output layers:\", model.fc.out_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lKSi3Fb8Aj9"
      },
      "source": [
        "## Step 3: Test ResNnet on test 'bird/forest' dataset\n",
        "\n",
        "We will test the model performance on test dataset before fine-tunning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cttC435X8Aj9"
      },
      "outputs": [],
      "source": [
        "# Helper Scripts\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "def unnormalize(img):\n",
        "    img = img * torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "    img = img + torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "    return img\n",
        "\n",
        "\n",
        "def display_images(images, true_labels, predicted_labels, class_names):\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    for i in range(len(images)):\n",
        "        ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n",
        "        img = unnormalize(images[i])\n",
        "        img = F.to_pil_image(img)\n",
        "        ax.imshow(img)\n",
        "        ax.set_title(f'True: {class_names[true_labels[i]]}\\nPred: {class_names[predicted_labels[i]]}', color=(\"green\" if true_labels[i] == predicted_labels[i] else \"red\"))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdmKJIqD8Aj-"
      },
      "outputs": [],
      "source": [
        "# use validation transforms\n",
        "test_path = Path(DATASET_PATH) / \"test\"\n",
        "test_folder = ImageFolder(test_path, transform=val_transform)\n",
        "test_dataset = DataLoader(test_folder, batch_size=4, shuffle=True)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    count = 0\n",
        "    for inputs, classes in test_dataset:\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        display_images(inputs, classes, preds, test_folder.classes)\n",
        "        if count >= 2:\n",
        "            break\n",
        "        count += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSP9gH4J8Aj_"
      },
      "source": [
        "## Step 4: Train ResNet\n",
        "\n",
        "1. Train Last Layer (FC)\n",
        "    - larger learning rate\n",
        "2. Fine-Tune ResNet\n",
        "    - smaller learning rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtVXIGo18Aj_"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
        "    \"\"\"\n",
        "    Train step that takes model, training and validation dataloaders, loss functions, optimizer, number of epochs and device\n",
        "    \"\"\"\n",
        "    # Train the model for the specified number of epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        # Set the model to train mode\n",
        "        model.train()\n",
        "\n",
        "        # Initialize the running loss and accuracy\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        # Iterate over the batches of the train loader\n",
        "        for inputs, labels in train_loader:\n",
        "            # Move the inputs and labels to the device\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Zero the optimizer gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimizer step\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the running loss and accuracy\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        # Calculate the train loss and accuracy\n",
        "        train_loss = running_loss / len(train_loader.dataset)\n",
        "        train_acc = running_corrects.double() / len(train_loader.dataset)\n",
        "\n",
        "        # Set the model to evaluation mode\n",
        "        model.eval()\n",
        "\n",
        "        # Initialize the running loss and accuracy\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        # Iterate over the batches of the validation loader\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                # Move the inputs and labels to the device\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Update the running loss and accuracy\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        # Calculate the validation loss and accuracy\n",
        "        val_loss = running_loss / len(val_loader.dataset)\n",
        "        val_acc = running_corrects.double() / len(val_loader.dataset)\n",
        "\n",
        "        # Print the epoch results\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], train loss: {train_loss:.4f}, train acc: {train_acc:.4f}, val loss: {val_loss:.4f}, val acc: {val_acc:.4f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jT-80Jmq8Aj_"
      },
      "source": [
        "### 4.1: Fine-tune the last layer for a few epochs\n",
        "\n",
        "Freeze all layers except FC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_oyheI_8Aj_"
      },
      "outputs": [],
      "source": [
        "# TODO:\n",
        "# freeze all model.parameters()\n",
        "# unfreeze model.fc.parameters()\n",
        "# check results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EACithoL8Aj_"
      },
      "outputs": [],
      "source": [
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.fc.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "model.to(device)\n",
        "train(model, train_dataset, val_dataset, loss_function, optimizer, num_epochs=20, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMcLU10f8Aj_"
      },
      "source": [
        "### 4.2: Fine-tune the entire model for a few epochs\n",
        "\n",
        "Unfreeze all the layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ucSArar8Aj_"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlafY-UF8AkA"
      },
      "outputs": [],
      "source": [
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model.to(device)\n",
        "train(model, train_dataset, val_dataset, loss_function, optimizer, num_epochs=10, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIK7wN1W8AkA"
      },
      "source": [
        "## Step 5: Test ResNnet on test 'bird/forest' dataset\n",
        "\n",
        "We will test the model performance on test dataset **after** fine-tunning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUJC3A_W8AkA"
      },
      "outputs": [],
      "source": [
        "# use validation transforms\n",
        "model.to('cpu')\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    count = 0\n",
        "    for inputs, classes in test_dataset:\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        display_images(inputs, classes, preds, test_folder.classes)\n",
        "        if count >= 20:\n",
        "            break\n",
        "        count += 1"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mlworkshop",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}